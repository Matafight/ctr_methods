{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self,features_size,embedding_size):\n",
    "        super(DeepFM,self).__init__()\n",
    "        \n",
    "        self.features_size = features_size\n",
    "        self.field_size = len(features_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        ## FM first order embedding\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in features_size])\n",
    "        ## FM second order embedding\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,self.embedding_size) for feature_size in features_size])\n",
    "        ## Deep part\n",
    "        self.dense_dim = self.field_size * self.embedding_size\n",
    "        self.fc_dim = 500\n",
    "        \n",
    "        \n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "                nn.Linear(dense_dim,fc_dim),\n",
    "                nn.BatchNorm1d(fc_dim),\n",
    "                nn.LeakyReLU(0.2, inplace=True)     \n",
    "                )\n",
    " \n",
    "        self.fc_layer2 = nn.Sequential(\n",
    "                nn.Linear(fc_dim,fc_dim),\n",
    "                nn.BatchNorm1d(fc_dim), \n",
    "                nn.LeakyReLU(0.2, inplace=True)     \n",
    "                )\n",
    "        \n",
    "    \n",
    "    def forward(self,xi,vi):\n",
    "        ## input shape: bacth_size * field_size\n",
    "        \n",
    "        first_order_embeddings = self.first_order_embeddings\n",
    "        second_order_embeddings = self.second_order_embeddings\n",
    "        field_size = self.field_size\n",
    "        ## FM first order part\n",
    "        first_order_output_tmp1 = [ (first_order_embeddings[i](xi[:,i]).t()*vi[:,i]).t() for i in range(field_size)]\n",
    "        first_order_output_tmp2 = torch.cat(first_order_output_tmp1,axis=1)\n",
    "        first_order_output = torch.sum(first_order_output_tmp2,axis=1)\n",
    "        \n",
    "        ## FM second order part\n",
    "        second_order_output_tmp1 = [(second_order_embeddings[i](xi[:,i]).t()*vi[:,i]).t() for i in range(field_size) ]\n",
    "        ## 计算第一个二阶项, 固定 field不变\n",
    "        sum_sec_order_output  = sum(second_order_output_tmp1)\n",
    "        squared_sec_order_output = sum_sec_order_output*sum_sec_order_output\n",
    "        sum_squared_sec_order_output = torch.sum(squared_sec_order_output,axis=1)/2\n",
    "        ## 计算第二个二阶项\n",
    "        squared_sec_list = [item*item for item in second_order_output_tmp1]\n",
    "        sum_squared_sec = sum(squared_sec_list)\n",
    "        sum_sum_squared_sec = torch.sum(sum_squared_sec,axis=1)/2\n",
    "        ## finally\n",
    "        second_order_output = sum_squared_sec_order_output-sum_sum_squared_sec\n",
    "        \n",
    "        ## Deep part\n",
    "        dense_input = torch.cat(second_order_output_tmp1,axis=1)\n",
    "        print(dense_input.shape)\n",
    "        fc1_output = self.fc_layer1(dense_input)\n",
    "        fc2_output = self.fc_layer2(fc1_output)\n",
    "        \n",
    "        ## sum all together\n",
    "        sum_all = first_order_output+second_order_output+ torch.sum(fc2_output,axis=1)\n",
    "        return sum_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## dataloader\n",
    "import pickle\n",
    "with open('./processed/deepfm_training.pickle','rb') as fh: \n",
    "    total_data = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xi =np.array(total_data['xi'],dtype=float)\n",
    "vi = np.array(total_data['vi'],dtype=float)\n",
    "label = np.array(total_data['label'],dtype=float)\n",
    "## convert numpy.ndarray to torch tensor object\n",
    "xi = torch.tensor(xi)\n",
    "vi = torch.tensor(vi)\n",
    "label=torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FM_Dataset(TensorDataset):\n",
    "    def __init__(self,xi,vi,y=None):\n",
    "        super(FM_Dataset,self).__init__()\n",
    "        self.xi=xi\n",
    "        self.vi=vi\n",
    "        self.y=y\n",
    "    def __len__(self):\n",
    "        return self.xi.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        if self.y is not None: \n",
    "            sample = {'xi':self.xi[index],'vi':self.vi[index],'y':self.y[index]}\n",
    "        else:\n",
    "            sample = {'xi':self.xi[index],'vi':self.vi[index]}\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = FM_Dataset(xi,vi,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "dataloader = DataLoader(dataset,shuffle=True,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 定义损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
