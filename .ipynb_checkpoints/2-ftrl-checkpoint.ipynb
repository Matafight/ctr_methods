{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import exp, log, sqrt\n",
    "\n",
    "# implementation taken from kaggle scripts:\n",
    "# https://www.kaggle.com/sudalairajkumar/outbrain-click-prediction/ftrl-starter-with-leakage-vars/code\n",
    "\n",
    "\n",
    "def hash_element(el, D):\n",
    "    h = hash(el) % D\n",
    "    if h < 0:\n",
    "        h = h + D\n",
    "    return h\n",
    "\n",
    "def hash_elements(elements, D):\n",
    "    return [hash_element(el, D) for el in elements]\n",
    "\n",
    "\n",
    "class FtrlProximal(object):\n",
    "    ''' Our main algorithm: Follow the regularized leader - proximal\n",
    "        In short,\n",
    "        this is an adaptive-learning-rate sparse logistic-regression with\n",
    "        efficient L1-L2-regularization\n",
    "        Reference:\n",
    "        http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf\n",
    "    '''\n",
    "\n",
    "    def __init__(self, alpha, beta, L1, L2, D, interactions):\n",
    "        # parameters\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.L1 = L1\n",
    "        self.L2 = L2\n",
    "\n",
    "        # feature related parameters\n",
    "        self.D = D\n",
    "\n",
    "        self.interactions = interactions\n",
    "\n",
    "        # model\n",
    "        # n: squared sum of past gradients\n",
    "        # z: weights\n",
    "        # w: lazy weights\n",
    "        self.n = [0.0] * (D + 1)\n",
    "        self.z = [0.0] * (D + 1)\n",
    "        self.w = {}\n",
    "\n",
    "    def to_indices(self, x):\n",
    "        res = hash_elements(x, self.D)\n",
    "\n",
    "        if self.interactions:\n",
    "            sorted_x = sorted(x)\n",
    "            len_x = len(sorted_x)\n",
    "\n",
    "            for i in range(len_x):\n",
    "                for j in range(i + 1, len_x):\n",
    "                    h = hash_element(sorted_x[i] + '_' + sorted_x[j], self.D)\n",
    "                    res.append(h)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_hashed = self.to_indices(x)\n",
    "        return self.predict_hashed(x_hashed)\n",
    "\n",
    "    def predict_hashed(self, x):\n",
    "        ''' Get probability estimation on x\n",
    "            INPUT:\n",
    "                x: features\n",
    "            OUTPUT:\n",
    "                probability of p(y = 1 | x; w)\n",
    "        '''\n",
    "\n",
    "        # parameters\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        L1 = self.L1\n",
    "        L2 = self.L2\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = {}\n",
    "\n",
    "        # wTx is the inner product of w and x\n",
    "        wTx = 0.\n",
    "\n",
    "        indices = [0]\n",
    "        for i in x:\n",
    "            indices.append(i + 1)\n",
    "\n",
    "        for i in indices:\n",
    "            sign = -1. if z[i] < 0 else 1.  # get sign of z[i]\n",
    "\n",
    "            # build w on the fly using z and n, hence the name - lazy weights\n",
    "            # we are doing this at prediction instead of update time is because\n",
    "            # this allows us for not storing the complete w\n",
    "            if sign * z[i] <= L1:\n",
    "                # w[i] vanishes due to L1 regularization\n",
    "                w[i] = 0.0\n",
    "            else:\n",
    "                # apply prediction time L1, L2 regularization to z and get w\n",
    "                w[i] = (sign * L1 - z[i]) / ((beta + sqrt(n[i])) / alpha + L2)\n",
    "\n",
    "            wTx += w[i]\n",
    "\n",
    "        # cache the current w for update stage\n",
    "        self.w = w\n",
    "\n",
    "        # bounded sigmoid function, this is the probability estimation\n",
    "        return 1.0 / (1.0 + exp(-max(min(wTx, 35.0), -35.0)))\n",
    "\n",
    "    def update(self, x, p, y):\n",
    "        ''' Update model using x, p, y\n",
    "            INPUT:\n",
    "                x: a list of indices\n",
    "                p: probability prediction of our model\n",
    "                y: answer\n",
    "            MODIFIES:\n",
    "                self.n: increase by squared gradient\n",
    "                self.z: weights\n",
    "        '''\n",
    "\n",
    "        # parameter\n",
    "        alpha = self.alpha\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = self.w\n",
    "\n",
    "        # gradient under logloss\n",
    "        g = p - y\n",
    "\n",
    "        indices = [0]\n",
    "        for i in x:\n",
    "            indices.append(i + 1)\n",
    "\n",
    "        # update z and n\n",
    "        for i in indices:\n",
    "            sigma = (sqrt(n[i] + g * g) - sqrt(n[i])) / alpha\n",
    "            z[i] += g - sigma * w[i]\n",
    "            n[i] += g * g\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x_hashed = self.to_indices(x)\n",
    "        p = self.predict_hashed(x_hashed)\n",
    "        self.update(x_hashed, p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementation of auc is taken from ml_metrics:\n",
    "# https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/auc.py\n",
    "\n",
    "def tied_rank(x):\n",
    "    \"\"\"\n",
    "    Computes the tied rank of elements in x.\n",
    "    This function computes the tied rank of elements in x.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list of numbers, numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    score : list of numbers\n",
    "            The tied rank f each element in x\n",
    "    \"\"\"\n",
    "    sorted_x = sorted(zip(x,range(len(x))))\n",
    "    r = [0 for k in x]\n",
    "    cur_val = sorted_x[0][0]\n",
    "    last_rank = 0\n",
    "    for i in range(len(sorted_x)):\n",
    "        if cur_val != sorted_x[i][0]:\n",
    "            cur_val = sorted_x[i][0]\n",
    "            for j in range(last_rank, i): \n",
    "                r[sorted_x[j][1]] = float(last_rank+1+i)/2.0\n",
    "            last_rank = i\n",
    "        if i==len(sorted_x)-1:\n",
    "            for j in range(last_rank, i+1): \n",
    "                r[sorted_x[j][1]] = float(last_rank+i+2)/2.0\n",
    "    return r\n",
    "\n",
    "def auc(actual, posterior):\n",
    "    \"\"\"\n",
    "    Computes the area under the receiver-operater characteristic (AUC)\n",
    "    This function computes the AUC error metric for binary classification.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list of binary numbers, numpy array\n",
    "             The ground truth value\n",
    "    posterior : same type as actual\n",
    "                Defines a ranking on the binary numbers, from most likely to\n",
    "                be positive to least likely to be positive.\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean squared error between actual and posterior\n",
    "    \"\"\"\n",
    "    r = tied_rank(posterior)\n",
    "    num_positive = len([0 for x in actual if x==1])\n",
    "    num_negative = len(actual)-num_positive\n",
    "    sum_positive = sum([r[i] for i in range(len(r)) if actual[i]==1])\n",
    "    auc = ((sum_positive - num_positive*(num_positive+1)/2.0) /\n",
    "           (num_negative*num_positive))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from time import time\n",
    "from csv import DictReader\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "spaces = re.compile(r' +')\n",
    "\n",
    "\n",
    "# model parameters\n",
    "\n",
    "alpha = 0.1\n",
    "beta = 0.0\n",
    "L1 = 2.0\n",
    "L2 = 0.0\n",
    "\n",
    "D = 2 ** 25\n",
    "\n",
    "interactions = True\n",
    "n_epochs = 1\n",
    "show_auc = False\n",
    "\n",
    "models = {}\n",
    "models['0'] = FtrlProximal(alpha, beta, L1, L2, D, interactions)\n",
    "models['1'] = FtrlProximal(alpha, beta, L1, L2, D, interactions)\n",
    "model_full  = FtrlProximal(alpha, beta, L1, L2, D, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning models...\n",
      "epoch 0...\n"
     ]
    }
   ],
   "source": [
    "# training the models\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "print('trainning models...')\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print('epoch %d...' % i)\n",
    "\n",
    "    with open('./processed/svm_features_train.csv', 'r') as f:\n",
    "        reader = DictReader(f)\n",
    "\n",
    "        cnt = 0\n",
    "        for row in reader:\n",
    "            y = int(row['clicked'])\n",
    "\n",
    "            x = spaces.split(row['ad_display_str'].strip())\n",
    "\n",
    "            if row['fold'] == '0':\n",
    "                fold = '1'\n",
    "            else: # '1'\n",
    "                fold = '0'\n",
    "\n",
    "            models[fold].fit(x, y)\n",
    "            model_full.fit(x, y)\n",
    "\n",
    "            cnt = cnt + 1\n",
    "            if cnt % 1000000 == 0:\n",
    "                print('processed %dth row' % cnt)\n",
    "\n",
    "\n",
    "print('training took %0.3fm' % ((time() - t0) / 60))\n",
    "\n",
    "\n",
    "# validation and oof prediction\n",
    "\n",
    "print('validating models...')\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "all_y = {'0': [], '1': []}\n",
    "all_pred = {'0': [], '1': []}\n",
    "\n",
    "f_pred = {}\n",
    "f_pred['0'] = open('ftrl_pred_0.txt', 'w')\n",
    "f_pred['0'].write('y_actual,y_pred\\n')\n",
    "\n",
    "f_pred['1'] = open('ftrl_pred_1.txt', 'w')\n",
    "f_pred['1'].write('y_actual,y_pred\\n')\n",
    "\n",
    "with open('./processed/svm_features_train.csv', 'r') as f:\n",
    "    reader = DictReader(f)\n",
    "\n",
    "    cnt = 0\n",
    "    for row in reader:\n",
    "        y = int(row['clicked'])\n",
    "        fold = row['fold']\n",
    "\n",
    "        x = spaces.split(row['ad_display_str'].strip())\n",
    "        y_pred = models[fold].predict(x)\n",
    "\n",
    "        all_y[fold].append(y)\n",
    "        all_pred[fold].append(y_pred)\n",
    "        f_pred[fold].write('%s,%s\\n' % (y, y_pred))\n",
    "\n",
    "        cnt = cnt + 1\n",
    "        if cnt % 1000000 == 0:\n",
    "            print('processed %dth row' % cnt)\n",
    "        if show_auc and cnt % 5000000 == 0:\n",
    "            auc0 = auc(all_y['0'], all_pred['0'])\n",
    "            auc1 = auc(all_y['1'], all_pred['1'])\n",
    "            print('auc: %.4f, %.4f' % (auc0, auc1))\n",
    "\n",
    "auc0 = auc(all_y['0'], all_pred['0'])\n",
    "auc1 = auc(all_y['1'], all_pred['1'])            \n",
    "print('final auc: %.4f, %.4f' % (auc0, auc1))\n",
    "\n",
    "f_pred['0'].close()\n",
    "f_pred['1'].close()    \n",
    "\n",
    "print('predict took %0.3fm' % ((time() - t0) / 60))\n",
    "del all_y, all_pred\n",
    "\n",
    "\n",
    "# predicting the results on test\n",
    "\n",
    "print('applying the model to the test data...')\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# f_pred = open('ftrl_pred_test.txt', 'w')\n",
    "# f_pred.write('y_pred\\n')\n",
    "\n",
    "# with open('./processed/svm_features_test.csv', 'r') as f:\n",
    "#     reader = DictReader(f)\n",
    "\n",
    "#     cnt = 0\n",
    "#     for row in reader:\n",
    "#         x = spaces.split(row['ad_display_str'].strip())\n",
    "#         y_pred = model_full.predict(x)\n",
    "#         f_pred.write('%s\\n' % y_pred)\n",
    "\n",
    "#         cnt = cnt + 1\n",
    "#         if cnt % 1000000 == 0:\n",
    "#             print('processed %dth row' % cnt)\n",
    "\n",
    "# f_pred.close()\n",
    "\n",
    "# print('predict took %0.3fm' % ((time() - t0) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
